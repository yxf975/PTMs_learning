{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Question_Pair_Classification.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"061da79005c34df39dd931d66d85b95d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_530d03b8afd5499a9eca3404fd99b891","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9bc2f0d66e8f4a7f8c59ccdf02c82f9f","IPY_MODEL_60624cb002f2449683141d551035dbfc"]}},"530d03b8afd5499a9eca3404fd99b891":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9bc2f0d66e8f4a7f8c59ccdf02c82f9f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1907d0f54eb84d22a1da27f2c957b5d0","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7bbaecebc1114cde9e546cde25502e48"}},"60624cb002f2449683141d551035dbfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f1fb7adbeb024734ba95d9ce87b44ce8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:20&lt;00:00, 21.4B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5c79f6f9ac7f43ee99e03fc26c603cb8"}},"1907d0f54eb84d22a1da27f2c957b5d0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7bbaecebc1114cde9e546cde25502e48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1fb7adbeb024734ba95d9ce87b44ce8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5c79f6f9ac7f43ee99e03fc26c603cb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6ee592635a846ff801b3a62d6ef66d4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_94fa4da17da844ab8c4bf320e1864f95","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d0cf8c4194340959156a46eb0de2caa","IPY_MODEL_6ce4ce0640f74badbc56ed06ec2b39aa"]}},"94fa4da17da844ab8c4bf320e1864f95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d0cf8c4194340959156a46eb0de2caa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0cf7539a932e42ddaca1fcf995e7d96c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e92e7054d6484126ad89227fcd4d21cd"}},"6ce4ce0640f74badbc56ed06ec2b39aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c1270439c5b1439c9ee3bf588f23623e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:05&lt;00:00, 74.2MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_681cf63569074977b67b4fd9e894b23c"}},"0cf7539a932e42ddaca1fcf995e7d96c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e92e7054d6484126ad89227fcd4d21cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1270439c5b1439c9ee3bf588f23623e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"681cf63569074977b67b4fd9e894b23c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Sw-T4seTP-fQ","executionInfo":{"status":"ok","timestamp":1607244726497,"user_tz":-60,"elapsed":8352,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"17c175dc-5d95-4633-c5e8-bcc63c7620e3"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/84/7bc03215279f603125d844bf81c3fb3f2d50fe8e511546eb4897e4be2067/transformers-4.0.0-py3-none-any.whl (1.4MB)\n","\u001b[K     |████████████████████████████████| 1.4MB 14.1MB/s \n","\u001b[?25hCollecting tokenizers==0.9.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 58.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 65.4MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=628228d6771f0f316da0036b0a499b507561063de84d05f10f272729583b1a21\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fy90rFC2QC36","executionInfo":{"status":"ok","timestamp":1607246852456,"user_tz":-60,"elapsed":3094,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"5d5d32fe-419b-49fd-eadf-ae91c0669ded"},"source":["# install gdown to download the shared files in google drive\n","!pip install gdown"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gdown in /usr/local/lib/python3.6/dist-packages (3.6.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from gdown) (4.41.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gdown) (2.23.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gdown) (1.24.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vCR8mPYNWhOg","executionInfo":{"status":"ok","timestamp":1607246790296,"user_tz":-60,"elapsed":8679,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"408abcf1-7c9f-4720-f8d7-aca76592b29c"},"source":["# download quora-question-pairs dataset \n","!gdown --id 1nAEIkp3tGBSIetFxojp2hRigp34L6eyW"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1nAEIkp3tGBSIetFxojp2hRigp34L6eyW\n","To: /content/quora-question-pairs.zip\n","324MB [00:05, 64.4MB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Y7tMrsrXdvg","executionInfo":{"status":"ok","timestamp":1607246947105,"user_tz":-60,"elapsed":5594,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"665b3a69-0831-4277-b8fe-31f3d1d9c222"},"source":["!unzip quora-question-pairs.zip\n","!unzip train.csv.zip"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  /content/quora-question-pairs.zip\n","  inflating: sample_submission.csv.zip  \n","  inflating: test.csv                \n","  inflating: test.csv.zip            \n","  inflating: train.csv.zip           \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mmRtfDbBCayc"},"source":["# Quora Question Pair"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0oMS4LB1QSU4","executionInfo":{"status":"ok","timestamp":1607247005490,"user_tz":-60,"elapsed":2915,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"e7634aa2-51ed-4850-c1a1-aa555302acf5"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","    n_gpu = torch.cuda.device_count()\n","\n","    print('There are %d GPU(s) available.' % n_gpu)\n","\n","    print('We will use the GPU:', [torch.cuda.get_device_name(i) for i in range(n_gpu)])\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: ['Tesla V100-SXM2-16GB']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_odHnVfHi3AF"},"source":["## all required package"]},{"cell_type":"code","metadata":{"id":"QdH6iHRtC4Hr"},"source":["import pandas as pd\n","import numpy as np\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import log_loss\n","\n","#import bert tokenizer\n","from transformers import  BertTokenizer\n","#import bert classification for finetuning\n","from transformers import BertForSequenceClassification\n","# import adamw optimizer\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","\n","import torch\n","from torch.utils.data import TensorDataset\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","import time\n","import datetime\n","import random\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":254},"id":"0k-8PolSC8ei","executionInfo":{"status":"ok","timestamp":1607247173237,"user_tz":-60,"elapsed":739,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"c088885d-edee-4833-bd32-376fdd799161"},"source":["# since the dataset is a little bit big, I just use a small part of the dataset aim to reduce the training time\n","\n","train_data = pd.read_csv(\"./train.csv\", index_col=\"id\",nrows = 50000)\n","train_data.head(6)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>qid1</th>\n","      <th>qid2</th>\n","      <th>question1</th>\n","      <th>question2</th>\n","      <th>is_duplicate</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>What is the step by step guide to invest in sh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n","      <td>What would happen if the Indian government sto...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>How can I increase the speed of my internet co...</td>\n","      <td>How can Internet speed be increased by hacking...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>Why am I mentally very lonely? How can I solve...</td>\n","      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>9</td>\n","      <td>10</td>\n","      <td>Which one dissolve in water quikly sugar, salt...</td>\n","      <td>Which fish would survive in salt water?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>11</td>\n","      <td>12</td>\n","      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n","      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    qid1  qid2  ...                                          question2 is_duplicate\n","id              ...                                                                \n","0      1     2  ...  What is the step by step guide to invest in sh...            0\n","1      3     4  ...  What would happen if the Indian government sto...            0\n","2      5     6  ...  How can Internet speed be increased by hacking...            0\n","3      7     8  ...  Find the remainder when [math]23^{24}[/math] i...            0\n","4      9    10  ...            Which fish would survive in salt water?            0\n","5     11    12  ...  I'm a triple Capricorn (Sun, Moon and ascendan...            1\n","\n","[6 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"mHLpV7eZP4sJ","executionInfo":{"status":"ok","timestamp":1607247182076,"user_tz":-60,"elapsed":746,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"527d4362-1390-4ccc-c5db-f40cf187c56d"},"source":["test_data = pd.read_csv(\"./test.csv\", index_col=\"test_id\",nrows = 1000)\n","test_data.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question1</th>\n","      <th>question2</th>\n","    </tr>\n","    <tr>\n","      <th>test_id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>How does the Surface Pro himself 4 compare wit...</td>\n","      <td>Why did Microsoft choose core m3 and not core ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Should I have a hair transplant at age 24? How...</td>\n","      <td>How much cost does hair transplant require?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What but is the best way to send money from Ch...</td>\n","      <td>What you send money to China?</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Which food not emulsifiers?</td>\n","      <td>What foods fibre?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>How \"aberystwyth\" start reading?</td>\n","      <td>How their can I start reading?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                 question1                                          question2\n","test_id                                                                                                      \n","0        How does the Surface Pro himself 4 compare wit...  Why did Microsoft choose core m3 and not core ...\n","1        Should I have a hair transplant at age 24? How...        How much cost does hair transplant require?\n","2        What but is the best way to send money from Ch...                      What you send money to China?\n","3                              Which food not emulsifiers?                                  What foods fibre?\n","4                         How \"aberystwyth\" start reading?                     How their can I start reading?"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"id":"Cqby8d78DIOM","executionInfo":{"status":"ok","timestamp":1607247183516,"user_tz":-60,"elapsed":749,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"4e85e2dc-86f2-4566-da52-edac57833f32"},"source":["# train_validation data split\n","X_train, X_val, y_train, y_val = train_test_split(train_data[[\"question1\", \"question2\"]], \n","                                                    train_data[\"is_duplicate\"], test_size=0.2, random_state=2020)\n","X_train.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>question1</th>\n","      <th>question2</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>136</th>\n","      <td>Does it matter whether humans are selfish or e...</td>\n","      <td>Does it matter whether humanity is evil or not?</td>\n","    </tr>\n","    <tr>\n","      <th>5292</th>\n","      <td>What is the treatment for Prostate Enlargement?</td>\n","      <td>What are treatments for prostate stones?</td>\n","    </tr>\n","    <tr>\n","      <th>1293</th>\n","      <td>What was Marc Srour like as a teenager?</td>\n","      <td>What is it like to be Marc Srour?</td>\n","    </tr>\n","    <tr>\n","      <th>25308</th>\n","      <td>What reasons do people have to not join Facebook?</td>\n","      <td>How can you invite people by email to join a F...</td>\n","    </tr>\n","    <tr>\n","      <th>12103</th>\n","      <td>Why are some people afraid of clowns?</td>\n","      <td>Why are people so scared of clowns?</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                               question1                                          question2\n","id                                                                                                         \n","136    Does it matter whether humans are selfish or e...    Does it matter whether humanity is evil or not?\n","5292     What is the treatment for Prostate Enlargement?           What are treatments for prostate stones?\n","1293             What was Marc Srour like as a teenager?                  What is it like to be Marc Srour?\n","25308  What reasons do people have to not join Facebook?  How can you invite people by email to join a F...\n","12103              Why are some people afraid of clowns?                Why are people so scared of clowns?"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"4bYEvdN_D1kN"},"source":["## convert data to Bert input"]},{"cell_type":"code","metadata":{"id":"uzvzJhtWEKFr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607247462450,"user_tz":-60,"elapsed":693,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"d0c9fac9-8e41-4086-dea5-27ee7ab395ab"},"source":["# load bert tokenizer\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n","\n","#calculate the maximum sentence length\n","max_len  = 0\n","for _, row in train_data.iterrows():\n","    max_len = max(max_len, len(tokenizer(row['question1'],row['question2'])[\"input_ids\"]))\n","\n","print(\"max token length of the input:\", max_len)\n","    \n","# set the maximum token length\n","max_length = pow(2,int(np.log2(max_len)))\n","print(\"max token length for BERT:\", max_length)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["max token length of the input: 329\n","max token length for BERT: 256\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uy0ZyU_0D8Tm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607247475059,"user_tz":-60,"elapsed":742,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"dcd0c538-3553-47db-fb16-3e968f9ccb4a"},"source":["# func to convert data to bert input\n","def convert_to_dataset_torch(data: pd.DataFrame, labels = pd.Series(data=None)) -> TensorDataset:\n","    input_ids = []\n","    attention_masks = []\n","    token_type_ids = []\n","    for _, row in tqdm(data.iterrows(), total=data.shape[0]):\n","        encoded_dict = tokenizer.encode_plus(row[\"question1\"], row[\"question2\"], max_length=max_length, pad_to_max_length=True, \n","                      return_attention_mask=True, return_tensors='pt', truncation=True)\n","        # Add the encoded sentences to the list.\n","        input_ids.append(encoded_dict['input_ids'])\n","        token_type_ids.append(encoded_dict[\"token_type_ids\"])\n","        # And its attention mask (simply differentiates padding from non-padding).\n","        attention_masks.append(encoded_dict['attention_mask'])\n","    \n","    # Convert the lists into tensors.\n","    input_ids = torch.cat(input_ids, dim=0)\n","    token_type_ids = torch.cat(token_type_ids, dim=0)\n","    attention_masks = torch.cat(attention_masks, dim=0)\n","    if labels.empty:\n","        return TensorDataset(input_ids, attention_masks, token_type_ids)\n","    else:\n","        labels = torch.tensor(labels.values)\n","        return TensorDataset(input_ids, attention_masks, token_type_ids, labels)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mg0AKrt6EuRS","executionInfo":{"status":"ok","timestamp":1607247545182,"user_tz":-60,"elapsed":52676,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"7f374510-f681-47e6-ddab-83cddb45621d"},"source":["train = convert_to_dataset_torch(data=X_train, labels=y_train)\n","validation = convert_to_dataset_torch(data=X_val, labels= y_val)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/40000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 40000/40000 [00:41<00:00, 964.21it/s]\n","100%|██████████| 10000/10000 [00:10<00:00, 979.41it/s]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"HlqunAwEMTUa"},"source":["## train"]},{"cell_type":"code","metadata":{"id":"7INEdxNGMVVP"},"source":["# set batch size for DataLoader(options from paper:16 or 32)\n","batch_size = 32\n","\n","# Create the DataLoaders for training and validation sets\n","train_dataloader = DataLoader(\n","            train,  \n","            sampler = RandomSampler(train), # Select batches randomly\n","            batch_size = batch_size \n","        )\n","\n","# For validation\n","validation_dataloader = DataLoader(\n","            validation, \n","            sampler = SequentialSampler(validation), # Pull out batches sequentially.\n","            batch_size = batch_size \n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":218,"referenced_widgets":["061da79005c34df39dd931d66d85b95d","530d03b8afd5499a9eca3404fd99b891","9bc2f0d66e8f4a7f8c59ccdf02c82f9f","60624cb002f2449683141d551035dbfc","1907d0f54eb84d22a1da27f2c957b5d0","7bbaecebc1114cde9e546cde25502e48","f1fb7adbeb024734ba95d9ce87b44ce8","5c79f6f9ac7f43ee99e03fc26c603cb8","e6ee592635a846ff801b3a62d6ef66d4","94fa4da17da844ab8c4bf320e1864f95","7d0cf8c4194340959156a46eb0de2caa","6ce4ce0640f74badbc56ed06ec2b39aa","0cf7539a932e42ddaca1fcf995e7d96c","e92e7054d6484126ad89227fcd4d21cd","c1270439c5b1439c9ee3bf588f23623e","681cf63569074977b67b4fd9e894b23c"]},"id":"EWByYxRoM7fv","executionInfo":{"status":"ok","timestamp":1607247566214,"user_tz":-60,"elapsed":55096,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"eb3621e7-9881-44ed-923d-5e3b0c9328e2"},"source":["# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\n","    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels=2, # The number of output labels--2  \n","    output_attentions=False, # Whether returns attentions weights.\n","    output_hidden_states=False, # Whether returns all hidden-states.\n",")\n","model.cuda()\n","if n_gpu > 1:\n","    model = torch.nn.DataParallel(model)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"061da79005c34df39dd931d66d85b95d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e6ee592635a846ff801b3a62d6ef66d4","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"eNf2BJ-fNRrK"},"source":["optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate\n","                  eps = 1e-8 # args.adam_epsilon\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x8uSZwxMNWNu"},"source":["# Number of training epochs\n","epochs = 3\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQaeob3rNf1l"},"source":["def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yCtqeNeH8oo"},"source":["def fit_batch(dataloader, model, optimizer, epoch):\n","    total_train_loss = 0\n","    \n","    for batch in tqdm(dataloader, desc=f\"Training epoch:{epoch+1}\", unit=\"batch\"):\n","        # Unpack batch from dataloader.\n","        input_ids = batch[0].to(device)\n","        attention_masks = batch[1].to(device)\n","        token_type_ids = batch[2].to(device)\n","        labels = batch[3].to(device)\n","        \n","        # clear any previously calculated gradients before performing a backward pass.\n","        model.zero_grad()\n","        \n","        # Perform a forward pass (evaluate the model on this training batch).\n","        outputs = model(input_ids, \n","                        token_type_ids=token_type_ids, \n","                        attention_mask=attention_masks, \n","                        labels=labels)\n","        loss = outputs[0]\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # normlization of the gradients to 1.0 to avoid exploding gradients\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","        \n","    return total_train_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aOoWt5MnHpLh"},"source":["def eval_batch(dataloader, model, metric=accuracy_score):\n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    predictions , predicted_labels = [], []\n","    \n","    for batch in tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\"):\n","        # Unpack batch from dataloader.\n","        input_ids = batch[0].to(device)\n","        attention_masks = batch[1].to(device)\n","        token_type_ids = batch[2].to(device)\n","        labels = batch[3].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions.\n","            outputs = model(input_ids, \n","                            token_type_ids=token_type_ids, \n","                            attention_mask=attention_masks,\n","                            labels=labels)\n","            loss = outputs[0]\n","            logits = outputs[1]\n","        total_eval_loss += loss.item()\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of validation sentences, and\n","        # accumulate it over all batches.\n","        y_pred = np.argmax(logits, axis=1).flatten()\n","        total_eval_accuracy += metric(label_ids, y_pred)\n","        \n","        predictions.extend(logits.tolist())\n","        predicted_labels.extend(y_pred.tolist())\n","    \n","    return total_eval_accuracy, total_eval_loss, predictions ,predicted_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IiyBzIMGLCYI"},"source":["def train(train_dataloader, validation_dataloader, model, optimizer, epochs):\n","    # We'll store a number of quantities such as training and validation loss, \n","    # validation accuracy, and timings.\n","    training_stats = []\n","    \n","    # Measure the total training time for the whole run.\n","    total_t0 = time.time()\n","    \n","    for epoch in range(0, epochs):\n","        # Measure how long the training epoch takes.\n","        t0 = time.time()\n","        \n","        # Reset the total loss for this epoch.\n","        total_train_loss = 0\n","        \n","        # Put the model into training mode. \n","        model.train()\n","        \n","        total_train_loss = fit_batch(train_dataloader, model, optimizer, epoch)\n","        \n","        # Calculate the average loss over all of the batches.\n","        avg_train_loss = total_train_loss / len(train_dataloader)\n","        \n","        # Measure how long this epoch took.\n","        training_time = format_time(time.time() - t0)\n","        \n","        t0 = time.time()\n","        \n","        # Put the model in evaluation mode--the dropout layers behave differently\n","        # during evaluation.\n","        model.eval()\n","        \n","\n","        total_eval_accuracy, total_eval_loss, _, _ = eval_batch(validation_dataloader, model)\n","        \n","        # Report the final accuracy for this validation run.\n","        avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","        print(\"\\n\")\n","        print(f\"score: {avg_val_accuracy}\")\n","    \n","        # Calculate the average loss over all of the batches.\n","        avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","        # Measure how long the validation run took.\n","        validation_time = format_time(time.time() - t0)\n","    \n","        print(f\"Validation Loss: {avg_val_loss}\")\n","        print(\"\\n\")\n","    \n","        # Record all statistics from this epoch.\n","        training_stats.append(\n","            {\n","                'epoch': epoch,\n","                'Training Loss': avg_train_loss,\n","                'Valid. Loss': avg_val_loss,\n","                'Valid. score.': avg_val_accuracy,\n","                'Training Time': training_time,\n","                'Validation Time': validation_time\n","            }\n","        )\n","        \n","\n","    print(\"\")\n","    print(\"Training complete!\")\n","\n","    print(f\"Total training took {format_time(time.time()-total_t0)}\")\n","    return training_stats"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bchJkVSLP4sK"},"source":["def predict(dataloader, model):\n","    prediction = torch.tensor([])\n","    \n","    for batch in tqdm(dataloader, desc=\"predicting\", unit=\"batch\"):\n","        # Unpack batch from dataloader.\n","        input_ids = batch[0].to(device)\n","        attention_masks = batch[1].to(device)\n","        token_type_ids = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():\n","            # Forward pass, calculate logit predictions.\n","            outputs = model(input_ids, \n","                            token_type_ids=token_type_ids, \n","                            attention_mask=attention_masks)\n","        logits = outputs[0]\n","        \n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu()\n","        # obtain the probabilty of each label\n","        prob = torch.nn.functional.softmax(logits)\n","        \n","        prediction = torch.cat((prediction, prob),0)\n","        \n","    pred_logits =prediction.numpy()\n","    pred_label = np.argmax(pred_logits, axis=1).flatten()\n","    print(\"done\")\n","    return (pred_label,pred_logits)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZPL2tNvnMQi5","executionInfo":{"status":"ok","timestamp":1607249442531,"user_tz":-60,"elapsed":1847841,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"d0e03f0b-873a-4b0c-c46d-7b750860e161"},"source":["# Set the seed value all over the place to make this reproducible.\n","seed_val = 2020\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","if n_gpu > 1:\n","    torch.cuda.manual_seed_all(seed_val)\n","\n","training_stats = train(train_dataloader, validation_dataloader, model, optimizer, epochs)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training epoch:1: 100%|██████████| 1250/1250 [09:29<00:00,  2.19batch/s]\n","Evaluating: 100%|██████████| 313/313 [00:45<00:00,  6.93batch/s]\n","Training epoch:2:   0%|          | 0/1250 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","score: 0.8563298722044729\n","Validation Loss: 0.33124485759498973\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Training epoch:2: 100%|██████████| 1250/1250 [09:30<00:00,  2.19batch/s]\n","Evaluating: 100%|██████████| 313/313 [00:45<00:00,  6.93batch/s]\n","Training epoch:3:   0%|          | 0/1250 [00:00<?, ?batch/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","score: 0.8654153354632588\n","Validation Loss: 0.3236829898001763\n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Training epoch:3: 100%|██████████| 1250/1250 [09:31<00:00,  2.19batch/s]\n","Evaluating: 100%|██████████| 313/313 [00:45<00:00,  6.92batch/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","\n","score: 0.8651158146964856\n","Validation Loss: 0.3816519981047835\n","\n","\n","\n","Training complete!\n","Total training took 0:30:47\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"vxYX6VI7QTrt","executionInfo":{"status":"ok","timestamp":1607249808465,"user_tz":-60,"elapsed":715,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"058acd1f-d7d6-464e-b3d9-f7c4e42d427b"},"source":["df_stats = pd.DataFrame(training_stats).set_index('epoch')\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. score.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.390552</td>\n","      <td>0.331245</td>\n","      <td>0.856330</td>\n","      <td>0:09:30</td>\n","      <td>0:00:45</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.242538</td>\n","      <td>0.323683</td>\n","      <td>0.865415</td>\n","      <td>0:09:30</td>\n","      <td>0:00:45</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.156890</td>\n","      <td>0.381652</td>\n","      <td>0.865116</td>\n","      <td>0:09:31</td>\n","      <td>0:00:45</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. score. Training Time Validation Time\n","epoch                                                                         \n","0           0.390552     0.331245       0.856330       0:09:30         0:00:45\n","1           0.242538     0.323683       0.865415       0:09:30         0:00:45\n","2           0.156890     0.381652       0.865116       0:09:31         0:00:45"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"sfvWu2y5P4sK"},"source":["# Predition for test set"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yprp4S7JP4sK","executionInfo":{"status":"ok","timestamp":1607251127625,"user_tz":-60,"elapsed":1815,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"ce82f7ac-5913-4cb7-8cea-21a589f65550"},"source":["# Create the DataLoader for test data.\n","prediction_data = convert_to_dataset_torch(test_data)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  0%|          | 0/1000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2142: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","100%|██████████| 1000/1000 [00:01<00:00, 963.05it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N4PKffm3P4sK","executionInfo":{"status":"ok","timestamp":1607251137367,"user_tz":-60,"elapsed":4898,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"689b4f45-6875-42ad-e5c7-646eef23f2ec"},"source":["y_pred,probs = predict(prediction_dataloader,model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["predicting:   0%|          | 0/32 [00:00<?, ?batch/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","predicting: 100%|██████████| 32/32 [00:04<00:00,  7.15batch/s]"],"name":"stderr"},{"output_type":"stream","text":["done\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0F33aob5gZ41","executionInfo":{"status":"ok","timestamp":1607251149621,"user_tz":-60,"elapsed":811,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"0ab8d8b5-230f-492f-f786-7f8969778304"},"source":["y_pred[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":82}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eMeNJVnvnDfi","executionInfo":{"status":"ok","timestamp":1607251155359,"user_tz":-60,"elapsed":657,"user":{"displayName":"Xuefeng Yin","photoUrl":"https://lh3.googleusercontent.com/-ddmqurum4Dk/AAAAAAAAAAI/AAAAAAAAAA4/H1iukjidaN0/s64/photo.jpg","userId":"01601649717182370319"}},"outputId":"90ff3e42-b458-4461-f2c0-568cb8c52889"},"source":["probs[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[9.9928904e-01, 7.1098027e-04],\n","       [9.0432817e-01, 9.5671751e-02],\n","       [9.9618608e-01, 3.8138814e-03],\n","       [9.9849987e-01, 1.5001176e-03],\n","       [9.8352069e-01, 1.6479332e-02]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"Bs_bSDxEolbJ"},"source":[""],"execution_count":null,"outputs":[]}]}